{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.9/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.9/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scape Quotes\n",
    "\n",
    "Scrape the quotes on https://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Get page content\n",
    "def get_page_content(url):\n",
    "    \"\"\"Fetches the HTML content of a URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve content from {url}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Quotes to Scrape</title>\n",
      "    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/main.css\">\n",
      "    \n",
      "    \n",
      "</head>\n",
      "<body>\n",
      "    <div class=\"container\">\n",
      "        <div class=\"row header-box\">\n",
      "            <div class=\"col-md-8\">\n",
      "                <h1>\n",
      "                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "                </h1>\n",
      "            </div>\n",
      "            <div cla\n"
     ]
    }
   ],
   "source": [
    "# Test Function 1\n",
    "test_url = \"https://quotes.toscrape.com/page/1/\"\n",
    "content1 = get_page_content(test_url)\n",
    "print(content1[:500])  # Print the first 500 characters to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function 2: Parse quotes from page content\n",
    "def parse_quotes_from_page(content):\n",
    "    \"\"\"Parses quotes, authors, and tags from the page content.\"\"\"\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    quotes_data = []\n",
    "\n",
    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "    for quote in quotes:\n",
    "        text = quote.find(\"span\", class_=\"text\").get_text()\n",
    "        author = quote.find(\"small\", class_=\"author\").get_text()\n",
    "        tags = [tag.get_text() for tag in quote.find_all(\"a\", class_=\"tag\")]\n",
    "        \n",
    "        quotes_data.append({\n",
    "            \"text\": text,\n",
    "            \"author\": author,\n",
    "            \"tags\": tags\n",
    "        })\n",
    "\n",
    "    return quotes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 3: Scrape one page based on the page number\n",
    "def scrape_one_page(page_num):\n",
    "    \"\"\"Scrapes quotes from a single page based on the page number.\"\"\"\n",
    "    page_url = f\"https://quotes.toscrape.com/page/{page_num}/\"\n",
    "    content = get_page_content(page_url)\n",
    "    \n",
    "    if content is None:\n",
    "        return []  # Return an empty list if the page couldn't be retrieved\n",
    "    \n",
    "    quotes = parse_quotes_from_page(content)\n",
    "    print(f\"Scraped page {page_num}\")\n",
    "    return quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'author': 'Albert Einstein',\n",
      "  'tags': ['change', 'deep-thoughts', 'thinking', 'world'],\n",
      "  'text': '“The world as we have created it is a process of our thinking. It '\n",
      "          'cannot be changed without changing our thinking.”'},\n",
      " {'author': 'J.K. Rowling',\n",
      "  'tags': ['abilities', 'choices'],\n",
      "  'text': '“It is our choices, Harry, that show what we truly are, far more '\n",
      "          'than our abilities.”'}]\n"
     ]
    }
   ],
   "source": [
    "# Test Function 2\n",
    "test_quotes = parse_quotes_from_page(content1)\n",
    "pprint(test_quotes[:2])  # Print the first 2 quotes to verify parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 1\n",
      "Total quotes on page 1: 10\n",
      "[{'author': 'Albert Einstein',\n",
      "  'tags': ['change', 'deep-thoughts', 'thinking', 'world'],\n",
      "  'text': '“The world as we have created it is a process of our thinking. It '\n",
      "          'cannot be changed without changing our thinking.”'},\n",
      " {'author': 'J.K. Rowling',\n",
      "  'tags': ['abilities', 'choices'],\n",
      "  'text': '“It is our choices, Harry, that show what we truly are, far more '\n",
      "          'than our abilities.”'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Function 3\n",
    "page_num = 1\n",
    "quotes_on_page_1 = scrape_one_page(page_num)\n",
    "print(f\"Total quotes on page {page_num}: {len(quotes_on_page_1)}\")\n",
    "pprint(quotes_on_page_1[:2])  # Display the first 3 quotes for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 2\n",
      "Total quotes on page 2: 10\n",
      "[{'author': 'Marilyn Monroe',\n",
      "  'tags': ['friends', 'heartbreak', 'inspirational', 'life', 'love', 'sisters'],\n",
      "  'text': \"“This life is what you make it. No matter what, you're going to \"\n",
      "          \"mess up sometimes, it's a universal truth. But the good part is you \"\n",
      "          \"get to decide how you're going to mess it up. Girls will be your \"\n",
      "          \"friends - they'll act like it anyway. But just remember, some come, \"\n",
      "          \"some go. The ones that stay with you through everything - they're \"\n",
      "          \"your true best friends. Don't let go of them. Also remember, \"\n",
      "          'sisters make the best friends in the world. As for lovers, well, '\n",
      "          \"they'll come and go too. And baby, I hate to say it, most of them - \"\n",
      "          'actually pretty much all of them are going to break your heart, but '\n",
      "          \"you can't give up because if you give up, you'll never find your \"\n",
      "          \"soulmate. You'll never find that half who makes you whole and that \"\n",
      "          \"goes for everything. Just because you fail once, doesn't mean \"\n",
      "          \"you're gonna fail at everything. Keep trying, hold on, and always, \"\n",
      "          \"always, always believe in yourself, because if you don't, then who \"\n",
      "          'will, sweetie? So keep your head high, keep your chin up, and most '\n",
      "          \"importantly, keep smiling, because life's a beautiful thing and \"\n",
      "          \"there's so much to smile about.”\"},\n",
      " {'author': 'J.K. Rowling',\n",
      "  'tags': ['courage', 'friends'],\n",
      "  'text': '“It takes a great deal of bravery to stand up to our enemies, but '\n",
      "          'just as much to stand up to our friends.”'}]\n"
     ]
    }
   ],
   "source": [
    "quotes_on_page_2 = scrape_one_page(2)\n",
    "print(f\"Total quotes on page 2: {len(quotes_on_page_2)}\")\n",
    "pprint(quotes_on_page_2[:2])  # Display the first 3 quotes for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape books\n",
    "\n",
    "Scrape books on https://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function 1\n",
    "books_url = \"https://books.toscrape.com\"\n",
    "content2 = get_page_content(books_url)\n",
    "# print(content[:500])  # Print the first 500 characters to check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 2: Parse books from page content and get URLs\n",
    "def parse_books_from_page(content):\n",
    "    \"\"\"Parses book titles, prices, availability, ratings, and URLs from the page content.\"\"\"\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    books_data = []\n",
    "\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    for book in books:\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").get_text().strip()\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").get_text().strip()\n",
    "        rating = book.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "        \n",
    "        # Get book URL (relative URL)\n",
    "        relative_url = book.h3.a[\"href\"]\n",
    "        book_url = f\"https://books.toscrape.com/{relative_url}\"\n",
    "        \n",
    "        books_data.append({\n",
    "            \"title\": title,\n",
    "            \"price\": price,\n",
    "            \"availability\": availability,\n",
    "            \"rating\": rating,\n",
    "            \"url\": book_url\n",
    "        })\n",
    "\n",
    "    return books_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'availability': 'In stock',\n",
      "  'price': 'Â£51.77',\n",
      "  'rating': 'Three',\n",
      "  'title': 'A Light in the Attic',\n",
      "  'url': 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'},\n",
      " {'availability': 'In stock',\n",
      "  'price': 'Â£53.74',\n",
      "  'rating': 'One',\n",
      "  'title': 'Tipping the Velvet',\n",
      "  'url': 'https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html'}]\n",
      "=== Total books on page: 20\n"
     ]
    }
   ],
   "source": [
    "# Test Function 2\n",
    "test_books = parse_books_from_page(content2)\n",
    "pprint(test_books[:2])  # Print the first 3 books to verify parsing\n",
    "print(f\"=== Total books on page: {len(test_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function 4\n",
    "book1_url = test_books[0][\"url\"]  # Take the URL of the first book from the previous test\n",
    "book1_content = get_page_content(book1_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 4: Scrape book details from the detail page\n",
    "def scrape_book_details(content):\n",
    "    \"\"\"Scrapes detailed information from a book's detail page.\"\"\"\n",
    "    # content = get_page_content(book_url)\n",
    "    \n",
    "    if content is None:\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    \n",
    "    # Extract details\n",
    "    upc = soup.find(\"th\", string=\"UPC\").find_next_sibling(\"td\").get_text()\n",
    "    product_type = soup.find(\"th\", string=\"Product Type\").find_next_sibling(\"td\").get_text()\n",
    "    price_excl_tax = soup.find(\"th\", string=\"Price (excl. tax)\").find_next_sibling(\"td\").get_text()\n",
    "    price_incl_tax = soup.find(\"th\", string=\"Price (incl. tax)\").find_next_sibling(\"td\").get_text()\n",
    "    tax = soup.find(\"th\", string=\"Tax\").find_next_sibling(\"td\").get_text()\n",
    "    availability = soup.find(\"th\", string=\"Availability\").find_next_sibling(\"td\").get_text()\n",
    "    num_reviews = soup.find(\"th\", string=\"Number of reviews\").find_next_sibling(\"td\").get_text()\n",
    "    description = soup.find(\"meta\", {\"name\": \"description\"})[\"content\"].strip()\n",
    "    \n",
    "    book_details = {\n",
    "        \"upc\": upc,\n",
    "        \"product_type\": product_type,\n",
    "        \"price_excl_tax\": price_excl_tax,\n",
    "        \"price_incl_tax\": price_incl_tax,\n",
    "        \"tax\": tax,\n",
    "        \"availability\": availability,\n",
    "        \"num_reviews\": num_reviews,\n",
    "        # \"description\": description\n",
    "    }\n",
    "    \n",
    "    return book_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upc': 'a897fe39b1053632',\n",
       " 'product_type': 'Books',\n",
       " 'price_excl_tax': 'Â£51.77',\n",
       " 'price_incl_tax': 'Â£51.77',\n",
       " 'tax': 'Â£0.00',\n",
       " 'availability': 'In stock (22 available)',\n",
       " 'num_reviews': '0'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1_detail = scrape_book_details(book1_content)\n",
    "book1_detail  # Display the details of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping book https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "scraping book https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "scraping book https://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "scraping book https://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "scraping book https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n"
     ]
    }
   ],
   "source": [
    "detailed_books = []\n",
    "for book in test_books[:5]:\n",
    "    print(\"scraping book\", book[\"url\"])\n",
    "    content = get_page_content(book[\"url\"])\n",
    "    detail = scrape_book_details(content)\n",
    "    detailed_books.append(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'upc': 'a897fe39b1053632',\n",
       "  'product_type': 'Books',\n",
       "  'price_excl_tax': 'Â£51.77',\n",
       "  'price_incl_tax': 'Â£51.77',\n",
       "  'tax': 'Â£0.00',\n",
       "  'availability': 'In stock (22 available)',\n",
       "  'num_reviews': '0'},\n",
       " {'upc': '90fa61229261140a',\n",
       "  'product_type': 'Books',\n",
       "  'price_excl_tax': 'Â£53.74',\n",
       "  'price_incl_tax': 'Â£53.74',\n",
       "  'tax': 'Â£0.00',\n",
       "  'availability': 'In stock (20 available)',\n",
       "  'num_reviews': '0'},\n",
       " {'upc': '6957f44c3847a760',\n",
       "  'product_type': 'Books',\n",
       "  'price_excl_tax': 'Â£50.10',\n",
       "  'price_incl_tax': 'Â£50.10',\n",
       "  'tax': 'Â£0.00',\n",
       "  'availability': 'In stock (20 available)',\n",
       "  'num_reviews': '0'},\n",
       " {'upc': 'e00eb4fd7b871a48',\n",
       "  'product_type': 'Books',\n",
       "  'price_excl_tax': 'Â£47.82',\n",
       "  'price_incl_tax': 'Â£47.82',\n",
       "  'tax': 'Â£0.00',\n",
       "  'availability': 'In stock (20 available)',\n",
       "  'num_reviews': '0'},\n",
       " {'upc': '4165285e1663650f',\n",
       "  'product_type': 'Books',\n",
       "  'price_excl_tax': 'Â£54.23',\n",
       "  'price_incl_tax': 'Â£54.23',\n",
       "  'tax': 'Â£0.00',\n",
       "  'availability': 'In stock (20 available)',\n",
       "  'num_reviews': '0'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
