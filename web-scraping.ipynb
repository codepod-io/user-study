{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scape Quotes\n",
    "\n",
    "Scrape the quotes on https://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function 1: Get page content\n",
    "def get_page_content(url):\n",
    "    \"\"\"Fetches the HTML content of a URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve content from {url}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Function 1\n",
    "test_url = \"https://quotes.toscrape.com/page/1/\"\n",
    "content = get_page_content(test_url)\n",
    "print(content[:500])  # Print the first 500 characters to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function 2: Parse quotes from page content\n",
    "def parse_quotes_from_page(content):\n",
    "    \"\"\"Parses quotes, authors, and tags from the page content.\"\"\"\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    quotes_data = []\n",
    "\n",
    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "    for quote in quotes:\n",
    "        text = quote.find(\"span\", class_=\"text\").get_text()\n",
    "        author = quote.find(\"small\", class_=\"author\").get_text()\n",
    "        tags = [tag.get_text() for tag in quote.find_all(\"a\", class_=\"tag\")]\n",
    "        \n",
    "        quotes_data.append({\n",
    "            \"text\": text,\n",
    "            \"author\": author,\n",
    "            \"tags\": tags\n",
    "        })\n",
    "\n",
    "    return quotes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function 3: Scrape one page based on the page number\n",
    "def scrape_one_page(page_num):\n",
    "    \"\"\"Scrapes quotes from a single page based on the page number.\"\"\"\n",
    "    page_url = f\"https://quotes.toscrape.com/page/{page_num}/\"\n",
    "    content = get_page_content(page_url)\n",
    "    \n",
    "    if content is None:\n",
    "        return []  # Return an empty list if the page couldn't be retrieved\n",
    "    \n",
    "    quotes = parse_quotes_from_page(content)\n",
    "    print(f\"Scraped page {page_num}\")\n",
    "    return quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Function 2\n",
    "test_quotes = parse_quotes_from_page(content)\n",
    "pprint(test_quotes[:2])  # Print the first 2 quotes to verify parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Test Function 3\n",
    "page_num = 1\n",
    "quotes_on_page_1 = scrape_one_page(page_num)\n",
    "print(f\"Total quotes on page {page_num}: {len(quotes_on_page_1)}\")\n",
    "pprint(quotes_on_page_1[:2])  # Display the first 3 quotes for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "quotes_on_page_2 = scrape_one_page(2)\n",
    "print(f\"Total quotes on page 2: {len(quotes_on_page_2)}\")\n",
    "pprint(quotes_on_page_2[:2])  # Display the first 3 quotes for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape books\n",
    "\n",
    "Scrape books on https://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Function 1\n",
    "books_url = \"https://books.toscrape.com\"\n",
    "content = get_page_content(books_url)\n",
    "# print(content[:500])  # Print the first 500 characters to check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function 2: Parse books from page content and get URLs\n",
    "def parse_books_from_page(content):\n",
    "    \"\"\"Parses book titles, prices, availability, ratings, and URLs from the page content.\"\"\"\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    books_data = []\n",
    "\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    for book in books:\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").get_text().strip()\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").get_text().strip()\n",
    "        rating = book.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "        \n",
    "        # Get book URL (relative URL)\n",
    "        relative_url = book.h3.a[\"href\"]\n",
    "        book_url = f\"https://books.toscrape.com/{relative_url}\"\n",
    "        \n",
    "        books_data.append({\n",
    "            \"title\": title,\n",
    "            \"price\": price,\n",
    "            \"availability\": availability,\n",
    "            \"rating\": rating,\n",
    "            \"url\": book_url\n",
    "        })\n",
    "\n",
    "    return books_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Function 2\n",
    "test_books = parse_books_from_page(content)\n",
    "pprint(test_books[:2])  # Print the first 3 books to verify parsing\n",
    "print(f\"=== Total books on page: {len(test_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Function 4\n",
    "book1_url = test_books[0][\"url\"]  # Take the URL of the first book from the previous test\n",
    "book1_content = get_page_content(book1_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function 4: Scrape book details from the detail page\n",
    "def scrape_book_details(content):\n",
    "    \"\"\"Scrapes detailed information from a book's detail page.\"\"\"\n",
    "    # content = get_page_content(book_url)\n",
    "    \n",
    "    if content is None:\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    \n",
    "    # Extract details\n",
    "    upc = soup.find(\"th\", string=\"UPC\").find_next_sibling(\"td\").get_text()\n",
    "    product_type = soup.find(\"th\", string=\"Product Type\").find_next_sibling(\"td\").get_text()\n",
    "    price_excl_tax = soup.find(\"th\", string=\"Price (excl. tax)\").find_next_sibling(\"td\").get_text()\n",
    "    price_incl_tax = soup.find(\"th\", string=\"Price (incl. tax)\").find_next_sibling(\"td\").get_text()\n",
    "    tax = soup.find(\"th\", string=\"Tax\").find_next_sibling(\"td\").get_text()\n",
    "    availability = soup.find(\"th\", string=\"Availability\").find_next_sibling(\"td\").get_text()\n",
    "    num_reviews = soup.find(\"th\", string=\"Number of reviews\").find_next_sibling(\"td\").get_text()\n",
    "    description = soup.find(\"meta\", {\"name\": \"description\"})[\"content\"].strip()\n",
    "    \n",
    "    book_details = {\n",
    "        \"upc\": upc,\n",
    "        \"product_type\": product_type,\n",
    "        \"price_excl_tax\": price_excl_tax,\n",
    "        \"price_incl_tax\": price_incl_tax,\n",
    "        \"tax\": tax,\n",
    "        \"availability\": availability,\n",
    "        \"num_reviews\": num_reviews,\n",
    "        # \"description\": description\n",
    "    }\n",
    "    \n",
    "    return book_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "book1_detail = scrape_book_details(book1_content)\n",
    "book1_detail  # Display the details of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "detailed_books = []\n",
    "for book in test_books[:5]:\n",
    "    print(\"scraping book\", book[\"url\"])\n",
    "    content = get_page_content(book[\"url\"])\n",
    "    detail = scrape_book_details(content)\n",
    "    detailed_books.append(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "detailed_books"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
